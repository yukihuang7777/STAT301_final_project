{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154ac2fb-6bde-4768-8ab7-46294a08b5f7",
   "metadata": {},
   "source": [
    "# Prediction of Spam \n",
    "### Jake Andersen-Lum, Stephen Hong, Yicheng Huang, Ella Ren\n",
    "### STAT301: Statistical Modelling for Data Science\n",
    "### March 31, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f3603-22b8-4f7a-9a59-59f8e4bfa927",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(infer)\n",
    "library(cowplot)\n",
    "library(broom)\n",
    "library(modelr)\n",
    "library(pROC)\n",
    "library(rsample)\n",
    "library(caret)\n",
    "#install.packages(\"glmnet\") # need this to run once before commenting out\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15d31b-9a2e-4129-836f-95ac5a0dc285",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As technology develops, an increasing number of users choose to use email as a method of communication. At the same time, the number of unsolicited spam emails has grown. This not only makes mailboxes cluttered and causes users to miss important emails, but it is also a burden on the ISP's system (Cranor & LaMacchia, 1998). Therefore, predicting spam is an important way to guarantee user access and maintain the integrity of the email system.\n",
    "\n",
    "Our research question is: Can we accurately predict whether an email is spam using the variables in our [email](https://www.openintro.org/data/index.php?data=email) dataset? The primary goal of this paper is prediction, and we hope to build a model that can accurately identify spam by using these features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa0523-c2fe-4633-a035-16df2d208502",
   "metadata": {},
   "source": [
    "## Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d12e87-6eed-406c-9538-7ef0d61f4d43",
   "metadata": {},
   "source": [
    "#### a) Data\n",
    "\n",
    "The dataset is called [email](https://www.openintro.org/data/index.php?data=email), which is sourced from OpenIntro, and the source is the first three months of 2012 for David Diez's Gmail Account.\n",
    "The dataset contains 3921 observations and 21 variables focusing on the information of incoming emails. This is an observational data.\n",
    "\n",
    "**Citation**: [email](https://www.openintro.org/data/index.php?data=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efd69b-965b-4ede-a044-7c8116902c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded the data from an open source\n",
    "email <- read_csv(url(\"https://www.openintro.org/data/csv/email.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404fb685-20d8-45f4-87d8-149e94d0e285",
   "metadata": {},
   "source": [
    "#### Variables information\n",
    "\n",
    "| Variable Name    | Type | Description |\n",
    "|---------|-----|-------|\n",
    "| spam   | Categorical  |  Indicator for whether the email was spam (1 = Yes, 0 = No).   |\n",
    "| to_multiple     | Categorical  |  Indicator for whether the email was addressed to more than one recipient (1 = Yes, 0 = No).   |\n",
    "| from | Categorical  |  Indicator for whether the message was listed as from anyone (1 = Yes, 0 = No).   |\n",
    "| cc   | Numerical  |  The number of people cc'ed (carbon copy) in the email.  |\n",
    "| sent_email     | Categorical  |  Indicator for whether the sender had been sent an email in the last 30 days (1 = Yes, 0 = No).   |\n",
    "| time | Numerical  |  Time at which email was sent.   |\n",
    "| image   | Numerical  |  The number of images attached in the email.   |\n",
    "|   attach   | Numerical  |  The number of attached files in the email.   |\n",
    "| dollar | Numerical  |  The number of times a dollar sign or the word \"dollar\" appeared in the email.   |\n",
    "|  winner  | Categorical  |  Indicates whether \"winner\" appeared in the email (Yes, No).   |\n",
    "|   inherit   | Numerical  |  The number of times \"inherit\" (or an extension, such as \"inheritance\") appeared in the email.   |\n",
    "| viagra | Numerical  |  The number of times \"viagra\" appeared in the email.   |\n",
    "|  password  | Numerical  |  The number of times \"password\" appeared in the email.   |\n",
    "|   num_char   | Numerical  |  The number of characters in the email, and the unit is thousands.   |\n",
    "| line_breaks | Numerical  |  The number of line breaks in the email (does not count text wrapping).   |\n",
    "|  format  | Categorical  |  Indicator for whether the email was written using HTML (1 = Yes, 0 = No).   |\n",
    "|   re_subj   | Categorical  |  Indicator for whether the subject started with \"Re:\", \"RE:\", \"re:\", or \"rE:\" (1 = Yes, 0 = No).  |\n",
    "| exclaim_subj | Categorical  |  Indicator for whether there was an exclamation point in the subject (1 = Yes, 0 = No).   |\n",
    "|  urgent_subj  | Categorical  |  Indicator for whether the word “urgent” was in the email subject (1 = Yes, 0 = No).   |\n",
    "|   exclaim_mess   | Numerical  |  The number of exclamation points in the email message.   |\n",
    "| number | Categorical  |  Indicates whether there was no number, a small number (under 1 million), or a big number (none, small, big).   |\n",
    "\n",
    "#### Dropped Variables\n",
    "- time: Time is removed from the dataset because emails may be sent from different time zones and cause noise.\n",
    "- viagra: Viagra is taken out of the dataset due to it being a binary variable but only ever taking on one value (0). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168bc41-d655-4cfd-acd0-2a99b2b692cc",
   "metadata": {},
   "source": [
    "#### b) Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b585f-b230-4ab2-87c1-f7f8146bdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected variables and converted categorical variables to factors\n",
    "email <- email |>\n",
    "    select(-time, -viagra) |>\n",
    "    mutate(across(c(spam, to_multiple, from, sent_email, winner, format, re_subj, exclaim_subj, urgent_subj, number), as.factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f732d96-7b21-4f95-8731-c50b3517a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Jake Andersen-Lum\n",
    "# Pivot to long format to get one column for variable names, and one for values\n",
    "email_long <- email |>\n",
    "  pivot_longer(cols = where(is.factor), names_to = \"variable\", values_to = \"value\")\n",
    "\n",
    "# Count and calculate proportions\n",
    "email_props <- email_long |>\n",
    "  group_by(variable, value) |>\n",
    "  summarise(n = n(), .groups = \"drop\") |>\n",
    "  group_by(variable) |>\n",
    "  mutate(prop = n / sum(n))\n",
    "\n",
    "# Plot\n",
    "bar_email <- ggplot(email_props, aes(x = variable, y = prop, fill = value)) +\n",
    "                  geom_bar(stat = \"identity\") +\n",
    "                  scale_y_continuous(labels = scales::percent) +\n",
    "                  labs(title = \"Proportions of Categorical Variables\",\n",
    "                       x = \"Variable\", y = \"Proportion\",\n",
    "                       fill = \"Category\") +\n",
    "                  theme_minimal() +\n",
    "                  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c838b-0072-4898-b710-8dbf2380b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Ella Ren\n",
    "# Contributors: Yicheng Huang (commented)\n",
    "\n",
    "# Compute correlation matrix for numeric variables\n",
    "email_matrix <- \n",
    "   cor(email[, sapply(email, is.numeric)], ) %>%\n",
    "   as_tibble(rownames = 'v1') %>%\n",
    "   pivot_longer(-v1, names_to = \"v2\", values_to = \"corr\")\n",
    "\n",
    "# Create a heatmap of the correlations\n",
    "heatmap_email <- \n",
    "  email_matrix %>%\n",
    "  ggplot(aes(x = v1, y = v2)) +\n",
    "  geom_tile(aes(fill = corr), color = \"white\") +\n",
    "  scale_fill_distiller(\"Correlation \\n\",\n",
    "      palette =  \"RdBu\",\n",
    "      direction = 1, \n",
    "      limits = c(-1, 1)\n",
    "    ) +\n",
    "    labs(x = \"\", y = \"\", title = \"Heatmap for Numerical and Binary Variables\") +\n",
    "    theme_minimal() +\n",
    "    theme(\n",
    "        axis.text.x = element_text(angle = 45, vjust = 1, size = 13, hjust = 1),\n",
    "        axis.text.y = element_text(vjust = 1, size = 13, hjust = 1),\n",
    "        legend.title = element_text(size = 13),\n",
    "        legend.text = element_text(size = 11),\n",
    "        legend.key.size = unit(1.3, \"cm\")\n",
    "    ) +\n",
    "    coord_fixed() +\n",
    "   geom_text(aes(x = v1, y = v2, label = round(corr, 2)), color = \"black\", size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a0f5d-37ec-42e0-b1a4-63dc2a83849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Jake Andersen-Lum\n",
    "# Contributors: Yicheng Huang (formatted & commented)\n",
    "\n",
    "# Convert \"format\" and \"has_attach\" into labeled categories\n",
    "email_scatter = email |> \n",
    "    mutate(format = factor(format, labels = c(\"Plain Text\", \"HTML\")),\n",
    "           has_attach = if_else(attach > 0, \"Yes\", \"No\"))\n",
    "\n",
    "# Create the scatterplot which facets by format and has_attach\n",
    "scatterplot_email = ggplot(email_scatter, aes(num_char, y = dollar + password, color = spam)) +\n",
    "    geom_point(alpha = 0.2, size = 2.5) +\n",
    "    facet_grid(format ~ has_attach, labeller = labeller(has_attach = c(\"No\" = \"No Attachment\", \"Yes\" = \"Has Attachment\"))) +\n",
    "    scale_x_continuous(name = \"Number of Characters (thousands)\") +\n",
    "    scale_y_continuous(name = \"Sum of Spam-related Keywords (dollar, password)\") +\n",
    "    labs(title = \"Exploring Email Spam: Keyword Counts Vs. Email Length\",\n",
    "         color = \"Spam Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15376dec-f4c2-42f0-86d7-aba17f9aeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep these commented out until the end otherwise lag\n",
    "#heatmap_email\n",
    "#scatterplot_email\n",
    "#bar_email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25e06c-b378-4984-976f-5efc9cfbb1fc",
   "metadata": {},
   "source": [
    "A potential problem coming from the heatmap is that there are certain variables with high correlation such as num_char + line_breaks and image + attach. These high correlation values could indicate a violation of multicollinearity when using such variables in a regression model. The scatterplots indicate the possibility of outliers in our data, especially in the bottom left plot as there are some extreme values regarding the sum of spam-related keywords, which could bias our outcomes and conclusions. However, after applying many different transformations to variables in the graph, there was no significant distinction from before, thus we chose to leave the variables as they are originally. \n",
    "\n",
    "The looking at the bar graph, from and urgent_subj all seem to only have one response. To further investigate, we found the number of rows corresponding to when from is equal to zero and the number of rows for when urgent_subj equals to 1. We saw that there are only three rows for when from is equal to one, therefore we chose to also get rid of that variable. urgent_subj equalling to one had a couple more rows, therefore we decided to keep it to see if LASSO eliminates it. \n",
    "\n",
    "No missing values were present for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836c9e9-9bda-47a0-bdb8-1ff516cf7943",
   "metadata": {},
   "source": [
    "#### c) Methods: Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb4cc5-13f9-4afd-983a-a1484cca6aad",
   "metadata": {},
   "source": [
    "#### Data Splitting and Model Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c7ee1-1a46-44ae-86be-6496ba3ebf07",
   "metadata": {},
   "source": [
    "Since we are creating a predictive model, we need to split the dataset into testing and training data to evaluate the model's performance. We will be creating a logistic regression model with the training data because our response variable (spam) is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e35c8-78ea-4fe1-a69b-f11f17a17918",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "# All group members developed this code together with the guidance of tutorial 10\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "email_split <- initial_split(email, prop = 0.7, strata = spam)\n",
    "email_training <- training(email_split)\n",
    "email_testing <- testing(email_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefb1f5-9d9d-43e3-970e-506791a36290",
   "metadata": {},
   "source": [
    "#### Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d64be6-3f2c-44e0-87c4-54776fa7be5c",
   "metadata": {},
   "source": [
    "There are many approaches we could take to estimate the model. Our group chose to implement LASSO as it is the method we were most familiar with. Using LASSO, we were able to select a subset of covariates for our model through the use of our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d891978-b69f-4223-b5eb-c5cc638231f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All group members developed this code together with the guidance of tutorial 10\n",
    "# Create model and response matrix for both training and testing sets \n",
    "matrix_X_train <- model.matrix(object = spam ~ ., data = email_training)[,-1]\n",
    "matrix_Y_train <- as.matrix(email_training$spam, ncol = 1)\n",
    "\n",
    "matrix_X_test <- model.matrix(object = spam ~ ., data = email_testing)[, -1]\n",
    "# Do we ever use this one?\n",
    "# matrix_Y_test <- as.matrix(email_testing$spam, ncol = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92ea91-35fa-4214-90f5-8220b4848876",
   "metadata": {},
   "source": [
    "In the above block, we turned the training and testing datasets into a design matrix for all covariates, excluding the first column of intercepts. The response (spam) is also turned into a matrix for the training set, this allows consistency of types when using LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b8031-ad76-4d91-9aeb-015403c9cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4)\n",
    "\n",
    "# All group members developed this code together with the guidance of tutorial 10\n",
    "# Finds lambda that produces the highest average AUC when LASSO penalty is used\n",
    "email_cv_lambda_LASSO <- cv.glmnet(\n",
    "    x = matrix_X_train, y = matrix_Y_train,\n",
    "    alpha = 1,\n",
    "    family = \"binomial\",\n",
    "    type.measure = \"auc\",\n",
    "    nfolds = 5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f273a-7d8f-4abb-8453-8463f34711b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LASSO feature selection:\")\n",
    "coef(email_cv_lambda_LASSO, s = \"lambda.min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f53fb2-99df-48f6-8955-2ed3a7b0d2a7",
   "metadata": {},
   "source": [
    "We used 5-fold cross-validation on our training data to fit logistic models. Additionally, it calculates the AUC, which evaluates how well the model is able to distinguish between the binary response. Through LASSO we selected all variables except num_char and exclaim_subj and end up fitting a logistic regression model using the training data without these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01940aa4-1b22-484a-911a-3ff72e64bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = glm(spam ~.-num_char-exclaim_subj-from, family = \"binomial\", data = email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c5a77-5ffa-43d2-ba94-5bb495c0bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main developer: Jake Andersen-Lum\n",
    "\n",
    "# ROC for the chosen model \n",
    "roc_glm_new <- roc(\n",
    "  response = email_testing$spam,\n",
    "  predictor = predict(chosen_model,\n",
    "                      newdata = email_testing,\n",
    "                      type = \"response\"))\n",
    "\n",
    "roc_glm_new$auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ebda3-8fa2-4691-92b4-1e4add995a79",
   "metadata": {},
   "source": [
    "We create ROC curve using the test data and get a AUC score of 0.906, this indicates decent performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387de65-0a7c-4e30-ae32-9bf7e1471d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Stephen Hong\n",
    "# code adapted from worksheet 10\n",
    "email_pred_class <- \n",
    "  round(predict(email_model, email_testing, type = \"response\"), 0)\n",
    "\n",
    "email_confusion_matrix <- \n",
    "    confusionMatrix(\n",
    "    data = as.factor(email_pred_class),\n",
    "    reference = as.factor(email_testing$spam),\n",
    "    positive = \"1\"\n",
    ")\n",
    "\n",
    "# store confusion matrix metrics in a table\n",
    "conf_mat_stats <- tibble(Sensitivity = c(email_confusion_matrix$byClass[\"Sensitivity\"]),\n",
    "                         Specificity = c(email_confusion_matrix$byClass[\"Specificity\"]),\n",
    "                         Precision = c(email_confusion_matrix$byClass[\"Precision\"]),\n",
    "                         Accuracy = c(email_confusion_matrix$overall[\"Accuracy\"]),\n",
    "                         Kappa = c(email_confusion_matrix$overall[\"Kappa\"]))\n",
    "\n",
    "#print(\"Table...........\")\n",
    "conf_mat_stats   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df4d45-accf-4772-82f2-0c375c5c716a",
   "metadata": {},
   "source": [
    "The trained model has a high accuracy when predicting on the test data, which is expected, but is not a good metric for this model's evaluation due to a large class imbalance with more non-spam emails in the dataset. We can see this through the very high specificity metric, as most of the emails in our dataset are not spam. A metric like precision is more valuable for evaluating the model's performance, as this metric tells us how many of the emails that the model classified as spam are actually spam emails. The precision of our model is decent, though the recall/sensitivity is low, which indicates that the model often classifies spam emails as non-spam. \n",
    "\n",
    "With the sensitivity being quite low, this indicates that the model is not very good at predicting when an email is spam. To try and counter this, we changed the threshold value. To determine that to change the threshold to, we looked at the ROC curve approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e8ebc-df8a-4d02-8e8a-78404a0b8ed6",
   "metadata": {},
   "source": [
    "Ok this is Jake's input here. Stuff is getting a bit cluttered so I'm just gonna explain what I'm trying to do here so it hopefully doesn't get too insanely complicated. Basically the ROC curve we're showing above is built on the test data, which is good in the sense that it gives a a better idea of how our model is performing. However, now we want to potentially pick a better decision threshold so that we can maximize sensitivity and specificity, and we want to do that using the ROC curve. However, if we use the curve above, that would violate the golden rule because we would be changing our model based on input from the test data. To fix this, I'll make a separate ROC curve based on the training data instead of the test data. This ROC curve will probably overestimate how good our model is, but it will ultimately allow the model to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bd131-34dd-451a-be95-a7cb24cea191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main developer: Jake Andersen-Lum\n",
    "\n",
    "# Predict on training set\n",
    "train_probs <- predict(chosen_model, newdata = email_training, type = \"response\")\n",
    "\n",
    "# ROC on training set\n",
    "roc_train <- roc(response = email_training$spam, predictor = train_probs)\n",
    "\n",
    "# Find threshold (on training set only)\n",
    "coords_train <- coords(roc_train, x = \"best\", best.method = \"closest.topleft\", transpose = FALSE)\n",
    "best_thresh <- coords_train$threshold\n",
    "\n",
    "plot(roc_train, print.auc = TRUE, col = \"red\", lwd = 3, lty = 2, main = \"Figure 3: ROC Curves for Training Spam Email Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6499a45-d6c5-452a-8ee7-2459385a4d48",
   "metadata": {},
   "source": [
    "Since our previous ROC curve used the testing set, we could not use that curve to find an appropriate threshold as it would be peeking at the testing data. Instead, a new ROC curve was created on the training set and the best decision threshold is the value closest to the top left corner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7563dba-bc28-488f-b06f-a3a390c8223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Get predicted probs and true labels\n",
    "# probs <- predict(chosen_model, newdata = email_training, type = \"response\")\n",
    "# truths <- as.factor(email_training$spam)\n",
    "\n",
    "# # Step 2: Manually compute precision, recall, F1 at multiple thresholds\n",
    "# thresholds <- seq(0.01, 0.99, by = 0.01)\n",
    "\n",
    "# pr_table <- map_dfr(thresholds, function(t) {\n",
    "#   preds <- ifelse(probs > t, \"1\", \"0\") |> factor(levels = c(\"0\", \"1\"))\n",
    "\n",
    "#   cm <- confusionMatrix(preds, truths, positive = \"1\")\n",
    "\n",
    "#   precision <- cm$byClass[\"Precision\"]\n",
    "#   recall    <- cm$byClass[\"Recall\"]\n",
    "#   f1        <- 2 * precision * recall / (precision + recall)\n",
    "\n",
    "#   tibble(threshold = t,\n",
    "#          precision = precision,\n",
    "#          recall = recall,\n",
    "#          f1 = f1)\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838627dc-cf04-4abb-ba4b-40265c57eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggplot(pr_table, aes(x = recall, y = precision)) +\n",
    "#   geom_line(color = \"blue\") +\n",
    "#   geom_point(aes(color = f1)) +\n",
    "#   labs(title = \"Precision-Recall Curve\",\n",
    "#        x = \"Recall\", y = \"Precision\") +\n",
    "#   theme_minimal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10af20-4c7f-499a-b6fb-0930106afacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_row <- pr_table %>% filter(f1 == max(f1, na.rm = TRUE))\n",
    "# best_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f148e-1d67-4d6b-91bb-cf0895cb395c",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea89dec-e21d-4f85-8dd2-8b52f4a66c3a",
   "metadata": {},
   "source": [
    "We use a confusion matrix below to interpret metrics of our model like precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e13df-f462-4178-ad43-4bf0764f83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "# Main developer: Stephen Hong\n",
    "\n",
    "# Predicted probabilities\n",
    "pred_probs_glm <- predict(chosen_model, newdata = email_testing, type = \"response\")\n",
    "\n",
    "# Define both thresholds\n",
    "thresholds <- c(best_thresh, 0.5)\n",
    "threshold_labels <- c(\"Custom Threshold Using ROC Curve\", \"Default 0.5\")\n",
    "\n",
    "# Initialize empty list to collect results\n",
    "conf_mat_stats_list <- list()\n",
    "\n",
    "# Loop through both thresholds\n",
    "for (i in 1:2) {\n",
    "  threshold <- thresholds[i]\n",
    "  label <- threshold_labels[i]\n",
    "  \n",
    "  # Apply threshold\n",
    "  email_pred_class <- ifelse(pred_probs_glm > threshold, 1, 0)\n",
    "\n",
    "  # Compute confusion matrix\n",
    "  cm <- confusionMatrix(\n",
    "    data = as.factor(email_pred_class),\n",
    "    reference = as.factor(email_testing$spam),\n",
    "    positive = \"1\"\n",
    "  )\n",
    "  \n",
    "  # Store results in a tibble\n",
    "precision <- cm$byClass[\"Precision\"]\n",
    "recall    <- cm$byClass[\"Recall\"]\n",
    "f1_score  <- 2 * precision * recall / (precision + recall)\n",
    "\n",
    "  conf_mat_stats_list[[i]] <- tibble(\n",
    "    Threshold = label,\n",
    "    Sensitivity = cm$byClass[\"Sensitivity\"],\n",
    "    Specificity = cm$byClass[\"Specificity\"],\n",
    "    Precision   = precision,\n",
    "    Recall      = recall,\n",
    "    Accuracy    = cm$overall[\"Accuracy\"],\n",
    "    Kappa       = cm$overall[\"Kappa\"],\n",
    "    F1          = f1_score\n",
    "  )\n",
    "}\n",
    "\n",
    "# Combine both rows into one table\n",
    "conf_mat_stats_compare <- bind_rows(conf_mat_stats_list)\n",
    "\n",
    "# Show result\n",
    "conf_mat_stats_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13563f8b-0df3-4bf7-ad6d-0ef8af4a291a",
   "metadata": {},
   "source": [
    "The trained model has a high accuracy when predicting on the test data, which is expected, but is not a good metric for this model's evaluation due to a large class imbalance with more non-spam emails in the dataset. We can see this through the very high specificity metric, as most of the emails in our dataset are not spam. A metric like precision is more valuable for evaluating the model's performance, as this metric tells us how many of the emails that the model classified as spam are actually spam emails. The precision of our model is decent, though the recall/sensitivity is low, which indicates that the model often classifies spam emails as non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73590d-f085-4079-810d-151472bc65db",
   "metadata": {},
   "source": [
    "## Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44275fa3-b625-470e-adb4-f157bf433684",
   "metadata": {},
   "source": [
    "## References\n",
    "Cranor, L. F., & LaMacchia, B. A. (1998). Spam! *Communications of the ACM, 41*(8), 74–83. https://doi.org/10.1145/280324.280336 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a82b90-7ce3-410e-bbbb-051b8f2047e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
